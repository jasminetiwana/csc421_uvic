{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC421 Fall 2021 Assignment 3 \n",
    "### Author: George Tzanetakis \n",
    "\n",
    "This notebook is based on the topics covered in **Chapter 12 - Quantifying Uncertainty **, **Chapter 13 Probabilistic Reasoning** from the book *Artificial Intelligence: A Modern Approach.*  You are welcome and actually it can be educational to look at the code at the aima-code repository as well as other code resources you can find on the web. However, make sure you understand any code that you incoporate. \n",
    "\n",
    "The assignment structure is as follows - each item is worth 1 point: \n",
    "\n",
    "1. Snakes and ladder simulation (Basic) - basic rolling and movement simulation, no ladders/snakes \n",
    "2. Snakes and ladder simulation (Basic) - multiple simulations and recording of number of rolls \n",
    "3. Snakes and ladder simulation (Expected) - adding of user-specified ladders/snakes \n",
    "4. Snakes and ladder simulation (Expected) - simulation to determine probability distribution of number of rolls \n",
    "5. Snakes and ladder simulation (Advanced) - exact inference + simulation with different ending rules \n",
    "6. Naive Bayes text classsification (Basic) - conditional probabilities for dictionary words \n",
    "7. Naive Bayes text classification (Basic) - markdown equations for Bernoulli \n",
    "8. Naive Bayes text classification (Expected) - prediction of movie review polarity \n",
    "9. Naive Bayes text classification (Expected) - classification accuracy and confusion matrix \n",
    "10. Naive Bayes text classification (Advanced) - probabilitistic generation of movie reviews \n",
    "\n",
    "The grading will be done in 0.5 increments. 1 point for correct answer, 0.5 points for partial or incorrect \n",
    "but reasonable answer and 0.0 for no answer or completely wrong answer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This question uses the board game of snakes and ladders to explore the concepts behind probability, \n",
    "stochastic simulation as well as exact and approximate inference. I assume that most of you are familiar \n",
    "with snakes and ladders. If you need a refresher check the following link: \n",
    "\n",
    "https://www.ymimports.com/pages/how-to-play-snakes-and-ladders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-8.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting numpy>=1.16\n",
      "  Using cached numpy-1.21.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, numpy, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 kiwisolver-1.3.2 matplotlib-3.4.3 numpy-1.21.4 pillow-8.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (Basic)  - 1 point\n",
    "\n",
    "Your first task will be to write a simple movement simulator on a snakes and ladders board. \n",
    "For this question you can ignore the snakes and ladders and just simply assume you only \n",
    "have to deal with moving. You will need to simulate rolling the die - this can be done \n",
    "by using the Python *random* module and the *randint* method. Your function *play_game* \n",
    "will take as input the length of the board (an integer), \"play\" the game by rolling the die \n",
    "multiple times until the sum of rolls is larger or equal to the length of the board.  (note: \n",
    "this is one of the possible and simplest end rules). The function should return the total \n",
    "number of rolls required to finish the the particular game that was played. Obviously \n",
    "this number will vary as it depends on the specific random rolls performed during the movement \n",
    "simulation. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "import random\n",
    "def play_game(length):\n",
    "    sum_of_rolls = 0\n",
    "    no_of_rolls = 0\n",
    "    while (sum_of_rolls < length):\n",
    "        roll = random.randint(1,6)\n",
    "        no_of_rolls += 1\n",
    "        sum_of_rolls += roll\n",
    "    return no_of_rolls\n",
    "\n",
    "play_game(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (Basic) - 1 point\n",
    "\n",
    "Your next task is to collect information about the probability distribution of number of rolls using the *play_game* function you implemented in the previous subquestion. Simulate playing the game 1000 times with a board length of 100 and record the number of rolls for each simulation. Show the histogram of the number of rolls for this simulation. You don't need to plot the histogram but can simply show the counts for each number of rolls as text. You can also create a plot using either the *matplotlib* or *bokeh* plotting frameworks. Make sure you include appropriate pip install and import statements in your notebook and check that it works in the Jupyterhub of the course. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of rolls: 26 count: 88\n",
      "no. of rolls: 32 count: 69\n",
      "no. of rolls: 34 count: 31\n",
      "no. of rolls: 31 count: 87\n",
      "no. of rolls: 25 count: 60\n",
      "no. of rolls: 29 count: 149\n",
      "no. of rolls: 27 count: 131\n",
      "no. of rolls: 30 count: 135\n",
      "no. of rolls: 28 count: 144\n",
      "no. of rolls: 33 count: 52\n",
      "no. of rolls: 35 count: 17\n",
      "no. of rolls: 23 count: 12\n",
      "no. of rolls: 24 count: 14\n",
      "no. of rolls: 22 count: 4\n",
      "no. of rolls: 36 count: 4\n",
      "no. of rolls: 38 count: 1\n",
      "no. of rolls: 37 count: 2\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "dict = {}\n",
    "for n in range(1,1001):\n",
    "    roll = play_game(100)\n",
    "    if roll in dict:\n",
    "        dict[roll] += 1\n",
    "    else:\n",
    "        dict[roll] = 1\n",
    "\n",
    "for i in dict:\n",
    "    print(\"no. of rolls:\", i, \"count:\", dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (Expected) 1 point \n",
    "\n",
    "Extent your *play_game* method to take as input a specification of snake and ladder positions and then perform the appropriate movement simulation. Just as before playing the game returns the number of rolls required to finish the game using the same simple end rule as the previous subquestions. \n",
    "\n",
    "<img src=\"snakes_ladders.png\" width=\"50%\"/>\n",
    "\n",
    "The snake and ladders positions will be encoded as a list of tuples. If the first number of the tuple is smaller than the second one it is ladder otherwise it is a snake. For example two of the snakes and one of the ladders\n",
    "in the board above would be represented as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(34, 6), (32, 10), (1, 38)]\n"
     ]
    }
   ],
   "source": [
    "snakeA = (34,6)\n",
    "snakeB = (32,10)\n",
    "ladderC = (1,38)\n",
    "snake_ladder_list = [snakeA,snakeB,ladderC]\n",
    "print(snake_ladder_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your play game function should take as input the snake and ladder specification. For testing and experiments use the board provided in the image above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "import random\n",
    "def play_game(length, snakes_ladders):\n",
    "    curr = 0\n",
    "    sum_of_rolls = 0\n",
    "    no_of_rolls = 0\n",
    "    while (curr < length):\n",
    "        roll = random.randint(1,6)\n",
    "        curr += roll\n",
    "        no_of_rolls += 1\n",
    "        sum_of_rolls += roll\n",
    "        for item in snakes_ladders:\n",
    "            if curr == item[0]:\n",
    "                curr = item[1]\n",
    "    return no_of_rolls\n",
    "\n",
    "\n",
    "play_game(100, snake_ladder_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 4 (EXPECTED) - 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the full game simulation that incoprorates the snakes and ladders, simulate 1000 games and record \n",
    "probability distribution of the number of rolls as a histogram similarly to the previous subquestion. \n",
    "Modify your code to support the following additional ending variations: \n",
    "\n",
    "* Exact landing: the piece needs to end exactly at the last square. If the roll exceeds the square then it is discarded but counted for the number of rolls \n",
    "* Bounce back variation:  If the roll is too high, the player's piece will bounce off the last space and move back. For example, if a player had four spaces to get to 100 and rolled a 6, the piece will move four spaces to 100, then “bounce back\" two spaces to 98.\n",
    "\n",
    "\n",
    "Show the histogram of the number of rolls for each ending variation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def play_game_exact(length, snakes_ladders):\n",
    "    curr = 0\n",
    "    sum_of_rolls = 0\n",
    "    no_of_rolls = 0\n",
    "    while (curr != length):\n",
    "        roll = random.randint(1,6)\n",
    "        curr += roll\n",
    "        no_of_rolls += 1\n",
    "        sum_of_rolls += roll\n",
    "        for item in snakes_ladders:\n",
    "            if curr == item[0]:\n",
    "                curr = item[1]\n",
    "        if (curr > length):\n",
    "            curr -= roll\n",
    "    return no_of_rolls\n",
    "\n",
    "list = []\n",
    "for i in range(0,1000):\n",
    "    list.append(play_game_exact(100, snake_ladder_list))\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(size=1000)\n",
    "\n",
    "plt.hist(list, density=True, bins=30)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');\n",
    "plt.show()\n",
    "\n",
    "def play_game_bounce(length, snakes_ladders):\n",
    "    curr = 0\n",
    "    sum_of_rolls = 0\n",
    "    no_of_rolls2 = 0\n",
    "    while (curr < length):\n",
    "        roll = random.randint(1,6)\n",
    "        if ((curr + roll) > length):\n",
    "            curr = (length-roll) + (length - curr)\n",
    "        else:\n",
    "            curr += roll\n",
    "        no_of_rolls2 += 1\n",
    "        sum_of_rolls += roll\n",
    "        for item in snakes_ladders:\n",
    "            if curr == item[0]:\n",
    "                curr = item[1]\n",
    "    return no_of_rolls2\n",
    "\n",
    "list2 = []\n",
    "for i in range(0,1000):\n",
    "    list2.append(play_game_bounce(100, snake_ladder_list))\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(size=1000)\n",
    "\n",
    "plt.hist(list2, density=True, bins=30)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 5 (ADVANCED) - 1 point \n",
    "\n",
    "In this question the goal is to perform exact probabilistic inference for the number of rolls. Rather than simulating the game and recording the number of moves you will need to compute systematically the probabilities of every possible sequence of rolls. You should use the simplified version of board movement with no snakes and ladders and the simple landing rule. As an example let's consider a very short board of 4 squares. The only sequence of 1 roll that finishes the game is rolling a 4 which has $P(4) = 1/6$. For two rolls we have more possibilities such as 1,3 or 3,1 or 2,2 or 2,3 or 3,2 etc. For example the probability of (1,3) is $P(1,3) = 1/6 * 1/6$. Your code should systematically calculate the right products and sums to come up with probabilities for \n",
    "each possible number of rolls. To make this a bit simpler consider a board of length $25$. I advise that you first start by looking at very short boards and checking some of the calculations by hand. \n",
    "\n",
    "Compare the results you get from exact inference with the results you get from approximate inference for the same board length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "def prob_inference(length):\n",
    "    probability = {}\n",
    "    for i in range(1,6):\n",
    "        curr = 0\n",
    "        probability[i] = 0\n",
    "        prob = 0\n",
    "        while curr < length:\n",
    "            curr += i\n",
    "            probability[i] = 1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra ideas (no credit) \n",
    "\n",
    "* Implement a GUI for showing the snakes/ladders board and support multiple players \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Categorization\n",
    "\n",
    "\n",
    "Text categorization is the task of assigning a given document to one of a fixed set of categories, on the basis of text it contains. Naive Bayes models are often used for this task. In these models, the query variable is\n",
    "the document category, and the effect variables are the presence/absence\n",
    "of each word in the language; the assumption is that words occur independently in documents within a given category (condititional independence), with frequencies determined by document category. Download the following file: http://www.cs.cornell.edu/People/pabo/movie-review-data/review_polarity.tar.gz containing a dataset that has been used for text mining consisting of movie reviews classified into negative and positive. You\n",
    "will see that there are two folders for the positivie and negative category and they each contain multiple text files with the reviews. You can find more information about the dataset at: \n",
    "http://www.cs.cornell.edu/People/pabo/movie-review-data/\n",
    "\n",
    "\n",
    "Our goal will be to build a simple Naive Bayes classifier for this dataset. More complicated approaches using term frequency and inverse document frequency weighting and many more words are possible but the basic concepts\n",
    "are the same. The goal is to understand the whole process so DO NOT use existing machine learning packages but rather build the classifier from scratch.\n",
    "\n",
    "Our feature vector representation for each text file will be simply a binary vector that shows which of the following words are present in the text file: Awful Bad Boring Dull Effective Enjoyable Great Hilarious. For example the text file cv996 11592.txt would be represented as (0, 0, 0, 0, 1, 0, 1, 0) because it contains Effective and Great but none of the other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 (Basic) -1 point\n",
    "\n",
    "Write code that parses the text files and calculates the probabilities for each dictionary word given the review polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "['awful:1.9% 19/1000', 'bad:25.5% 255/1000', 'boring:4.8% 48/1000', 'dull:2.3% 23/1000', 'effective:12.0% 120/1000', 'enjoyable:9.5% 95/1000', 'great:40.8% 408/1000', 'hilarious:12.5% 125/1000']\n",
      "neg\n",
      "['awful:10.1% 101/1000', 'bad:50.5% 505/1000', 'boring:16.9% 169/1000', 'dull:9.1% 91/1000', 'effective:4.6% 46/1000', 'enjoyable:5.3% 53/1000', 'great:28.6% 286/1000', 'hilarious:5.0% 50/1000']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "#wget http://www.cs.cornell.edu/People/pabo/movie-review-data/review_polarity.tar.gz\n",
    "#tar xyzf review_polarity.tar.gz\n",
    "\n",
    "import os\n",
    "\n",
    "path = \"./txt_sentoken\"\n",
    "data = []\n",
    "polarity = []\n",
    "pols = ['neg', 'pos']\n",
    "negvectors = []\n",
    "posvectors = []\n",
    "sumnegvectors = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "sumposvectors = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for index, pol in enumerate(pols):\n",
    "    files = os.listdir(os.path.join(path, pol))\n",
    "    for file in files:\n",
    "        masterlist = []\n",
    "        with open(os.path.join(path, pol, file)) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                list = line.split(\" \")\n",
    "                masterlist += list\n",
    "            data.append(masterlist)\n",
    "            polarity.append(index)\n",
    "words = ['awful', 'bad', 'boring', 'dull', 'effective', 'enjoyable', 'great', 'hilarious']\n",
    "for i, text in enumerate(data):\n",
    "    #vector = ['0', '0', '0', '0', '0', '0', '0', '0']\n",
    "    vector = [0, 0, 0, 0, 0, 0 ,0, 0]\n",
    "    for wordi, word in enumerate(words):\n",
    "        for item in text:\n",
    "            if word == item:\n",
    "                vector[wordi] = 1\n",
    "    if polarity[i] == 0: #negative review\n",
    "        negvectors.append(vector)\n",
    "        for j, item in enumerate(vector):\n",
    "            if vector[j] == 1:\n",
    "                sumnegvectors[j] += 1\n",
    "    else:\n",
    "        posvectors.append(vector) #pos review\n",
    "        for j, item in enumerate(vector):\n",
    "            if vector[j] == 1:\n",
    "                sumposvectors[j] += 1\n",
    "\n",
    "for i in range(0,8):\n",
    "    sumnegvectors[i] = words[i] + \":\" + str(sumnegvectors[i]/10) + \"%\" + \" \" + str(sumnegvectors[i]) + \"/\" + str(1000)\n",
    "    sumposvectors[i] = words[i] + \":\" + str(sumposvectors[i]/10) + \"%\" + \" \" + str(sumposvectors[i]) + \"/\" + str(1000)\n",
    "\n",
    "print(\"pos\")\n",
    "print(sumposvectors)\n",
    "print(\"neg\")\n",
    "print(sumnegvectors)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7 (Basic)  - 1 point \n",
    "\n",
    "Explain how the probability estimates for each dictionary word given the review polarity can be combined to form a Naive Bayes classifier. You can look up Bernoulli Bayes model for this simple model where only presence/absence of a word is modeled.\n",
    "\n",
    "Your answer should be a description of the process with equations and a specific example as markdown text NOT python code. You will write the code in the next question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1000 neg reviews and 1000 pos review so P(neg) = 1/2 and P(pos) = 1/2.\n",
    "\n",
    "Using the probability estimates for each word from the previous question, a given vector can be classified into a category by calculating the posterior probability for each category for the given vector and whichever has the highest probability is the correct category.\n",
    "\n",
    "The posterior probability for each category is calculated by the formula\n",
    "    P(C) * Π{t=1to8} (vector{t} * P(w{t}|S) + (1-vector{t} )(1-P(w{t} |S))\n",
    "Say we want to classify vector = [1, 0, 0, 1, 1, 1, 0, 1], then using our estimates from the previous question we have:\n",
    "    1/2*(0.122 * 1-0.545 * 1-0.175 * 0.101 * 0.086 * 0.054 * 1-0.32 * 0.059) for the neg category and \n",
    "    1/2*(0.034 * 1-0.28 * 1-0.054 * 0.025 * 0.154 * 0.096 * 1-0.485 * 0.132) for the pos category\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 8 (EXPECTED) 1 point\n",
    "\n",
    "Write Python code for classifying a particular test instance (in our case movie review) following a Bernolli Bayes approach. Your code should calculate the likelihood the review is positive given the correspondng conditional probabilities for each dictionary word as well as the likelihood the review is negative given the corresponding conditional probabilities for each dictionary word. Check that your code works by providing a few example cases of prediction. Your code should be written from \"scratch\" and only use numpy/scipy but **NOT** machine learning libraries like scikit-learn or tensorflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg 21.015326786260605%\n",
      "pos 9.598463351434743%\n",
      "neg 0.00013166223360288573%\n",
      "pos 0.0007654492700568%\n",
      "neg 0.2249407959261538%\n",
      "pos 0.06913659076663682%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "pos = [0.019, 0.255, 0.048, 0.023, 0.12, 0.095, 0.408, 0.125]\n",
    "neg = [0.101, 0.505, 0.169, 0.091, 0.046, 0.053, 0.286, 0.05]\n",
    "test = [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "test2 = [1, 0, 0, 0, 1, 1, 1, 1]\n",
    "test3 = [0, 1, 1, 0, 0, 0, 0, 1]\n",
    "\n",
    "def likelihood(review, word_probs): \n",
    "    probability_product = 1.0 \n",
    "    for (i,w) in enumerate(test_review): \n",
    "        if (w==1): \n",
    "            probability = word_probs[i]\n",
    "        else: \n",
    "            probability = 1.0 - word_probs[i]\n",
    "        probability_product *= probability \n",
    "    return probability_product\n",
    "\n",
    "print('neg' + \" \" + str(likelihood(test, neg)*100) + \"%\")\n",
    "print('pos' + \" \" + str(likelihood(test, pos)*100) + \"%\")\n",
    "print('neg' + \" \" + str(likelihood(test2, neg)*100) + \"%\")\n",
    "print('pos' + \" \" + str(likelihood(test2, pos)*100) + \"%\")\n",
    "print('neg' + \" \" + str(likelihood(test3, neg)*100) + \"%\")\n",
    "print('pos' + \" \" + str(likelihood(test3, pos)*100) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 9 (EXPECTED) 1 point \n",
    "\n",
    "\n",
    "Calculate the classification accuracy and confusion matrix that you would obtain using the whole data set for both training and testing. Do not use machine learning libraries like scikit-learn or tensorflow for this only the basic numpy/scipy stuff.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 67.4%\n",
      "+----------------+-------------------+-------------------+\n",
      "|                | Actual Neg Review | Actual Pos Review |\n",
      "+----------------+-------------------+-------------------+\n",
      "| Predicted Neg  |        592        |        244        |\n",
      "| Predicted Pos  |        408        |        756        |\n",
      "+----------------+-------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "#Confusion matrix is the results of your classifier: TP (pos classified pos, \n",
    "#TN (neg classified neg), FP (neg classified pos), FN. Accuracy is TP+TN/total classified\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "posclasspos = 0\n",
    "negclassneg = 0\n",
    "\n",
    "for i in range(0, len(posvectors)):\n",
    "    prob_neg = likelihood(posvectors[i], neg)\n",
    "    prob_pos = likelihood(posvectors[i], pos)\n",
    "    if prob_neg < prob_pos:\n",
    "        posclasspos += 1\n",
    "        \n",
    "for i in range(0, len(negvectors)):\n",
    "    prob_neg1 = likelihood(negvectors[i], neg)\n",
    "    prob_pos1 = likelihood(negvectors[i], pos)\n",
    "    if prob_neg1 > prob_pos1:\n",
    "        negclassneg += 1\n",
    "\n",
    "accuracy = (posclasspos + negclassneg)/2000\n",
    "print(\"accuracy:\", str(accuracy*100) + \"%\")\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names= [\" \", \"Actual Neg Review\", \"Actual Pos Review\"]\n",
    "x.add_row([\"Predicted Neg\", negclassneg , 1000-posclasspos])\n",
    "x.add_row([\"Predicted Pos \", 1000-negclassneg, posclasspos])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 10 (ADVANCED) 1 point \n",
    "\n",
    "One can consider the Naive Bayes classifier a generative model that can generate binary feature vectors using the associated probabilities from the training data. The idea is similar to how we do direct sampling in Bayesian Networks and depends on generating random number from a discrete distribution. Describe how you would generate random movie reviews consisting solely of the words from the dictionary using your model. Show 5 examples of randomly generated positive reviews and 5 examples of randomly generated negative reviews. Each example should consists of a subset of the words in the dictionary. Hint: use probabilities to generate both the presence and absence of a word. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive review: ['bad', 'bad', 'great', 'great', 'bad']\n",
      "Negative review: ['great', 'awful', 'boring', 'enjoyable', 'great']\n",
      "Positive review: ['great', 'great', 'effective', 'great', 'bad']\n",
      "Negative review: ['great']\n",
      "Positive review: ['great', 'great', 'enjoyable']\n",
      "Negative review: ['dull', 'boring', 'enjoyable']\n",
      "Positive review: ['bad']\n",
      "Negative review: ['awful', 'bad', 'bad', 'great', 'bad']\n",
      "Positive review: ['hilarious', 'effective', 'bad', 'great']\n",
      "Negative review: ['dull', 'boring', 'boring', 'enjoyable', 'bad']\n"
     ]
    }
   ],
   "source": [
    "pos_prob = [0.019, 0.255, 0.048, 0.023, 0.12, 0.095, 0.408, 0.125]\n",
    "neg_prob = [0.101, 0.505, 0.169, 0.091, 0.046, 0.053, 0.286, 0.05]\n",
    "words = ['awful', 'bad', 'boring', 'dull', 'effective', 'enjoyable', 'great', 'hilarious']\n",
    "pos_prob2 = []\n",
    "neg_prob2 = []\n",
    "for item in pos_prob:\n",
    "    item = item/sum(pos_prob)\n",
    "    pos_prob2.append(item)\n",
    "for item in neg_prob:\n",
    "    item = item/sum(neg_prob)\n",
    "    neg_prob2.append(item)\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"Positive review:\", [np.random.choice(words, p=pos_prob2) for i in range((random.randint(1,5)))])\n",
    "    print(\"Negative review:\", [np.random.choice(words, p=neg_prob2) for i in range((random.randint(1,5)))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra ideas (no credit) \n",
    "\n",
    "* Check the associated README file and see what convention is used for the 10-fold cross-validation. Calculate the classification accuracy and confusion matrix using the recommended 10-fold cross-validation. Again do NOT use \n",
    "ML libraries such as scikit-learn or tensorflow and just use numpy/scipy. \n",
    "* Implement the all the question using a ML library such as scikit-learn or tensorflow and a Naive Bayes Bernoulli classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
